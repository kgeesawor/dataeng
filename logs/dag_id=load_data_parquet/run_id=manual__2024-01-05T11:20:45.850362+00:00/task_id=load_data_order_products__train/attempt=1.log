[2024-01-05T11:40:45.499+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: load_data_parquet.load_data_order_products__train manual__2024-01-05T11:20:45.850362+00:00 [queued]>
[2024-01-05T11:40:45.526+0000] {taskinstance.py:1957} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: load_data_parquet.load_data_order_products__train manual__2024-01-05T11:20:45.850362+00:00 [queued]>
[2024-01-05T11:40:45.527+0000] {taskinstance.py:2171} INFO - Starting attempt 1 of 1
[2024-01-05T11:40:45.630+0000] {taskinstance.py:2192} INFO - Executing <Task(PythonOperator): load_data_order_products__train> on 2024-01-05 11:20:45.850362+00:00
[2024-01-05T11:40:45.638+0000] {standard_task_runner.py:60} INFO - Started process 620 to run task
[2024-01-05T11:40:45.647+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'load_data_parquet', 'load_data_order_products__train', 'manual__2024-01-05T11:20:45.850362+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/load_data_parquet.py', '--cfg-path', '/tmp/tmpla4832bz']
[2024-01-05T11:40:45.651+0000] {standard_task_runner.py:88} INFO - Job 34: Subtask load_data_order_products__train
[2024-01-05T11:40:45.887+0000] {task_command.py:423} INFO - Running <TaskInstance: load_data_parquet.load_data_order_products__train manual__2024-01-05T11:20:45.850362+00:00 [running]> on host edef6e683abd
[2024-01-05T11:40:46.150+0000] {local_task_job_runner.py:121} ERROR - Received SIGTERM. Terminating subprocesses
[2024-01-05T11:40:46.152+0000] {process_utils.py:131} INFO - Sending 15 to group 620. PIDs of all processes in the group: [620]
[2024-01-05T11:40:46.153+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 620
[2024-01-05T11:40:46.160+0000] {taskinstance.py:2451} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-01-05T11:40:46.206+0000] {taskinstance.py:2699} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2335, in _run_raw_task
    self._execute_task_with_callbacks(context, test_mode, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2470, in _execute_task_with_callbacks
    RenderedTaskInstanceFields.write(rtif)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/usr/local/lib/python3.8/contextlib.py", line 120, in __exit__
    next(self.gen)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 39, in create_session
    session.commit()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1454, in commit
    self._transaction.commit(_to_root=self.future)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 839, in commit
    trans.commit()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2469, in commit
    self._do_commit()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2659, in _do_commit
    self._connection_commit_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2630, in _connection_commit_impl
    self.connection._commit_impl()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1096, in _commit_impl
    self._handle_dbapi_exception(e, None, None, None, None)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2138, in _handle_dbapi_exception
    util.raise_(exc_info[1], with_traceback=exc_info[2])
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 1094, in _commit_impl
    self.engine.dialect.do_commit(self.connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 686, in do_commit
    dbapi_connection.commit()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 2453, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2024-01-05T11:40:46.240+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=load_data_parquet, task_id=load_data_order_products__train, execution_date=20240105T112045, start_date=20240105T114045, end_date=20240105T114046
[2024-01-05T11:40:46.287+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 34 for task load_data_order_products__train (Task received SIGTERM signal; 620)
[2024-01-05T11:40:46.327+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=620, status='terminated', exitcode=1, started='11:40:45') (620) terminated with exit code 1
[2024-01-05T11:40:46.328+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 143
[2024-01-05T11:40:46.381+0000] {taskinstance.py:3281} INFO - 0 downstream tasks scheduled from follow-on schedule check
